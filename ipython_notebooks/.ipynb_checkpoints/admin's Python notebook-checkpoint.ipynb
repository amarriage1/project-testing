{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "creator": "admin",
    "createdOn": 1682697138074,
    "tags": [],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: load a DSS dataset as a Pandas dataframe\nmydataset \u003d dataiku.Dataset(\"mydataset\")\nmydataset_df \u003d mydataset.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nimport time\nclient \u003d dataiku.api_client()\n\np \u003d client.get_project(\"DKU_CHURN\")\nd \u003d p.get_dataset(\"customers_copy\")\n\nd.clear()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataikuapi\nimport json\n\n# Source DSS instance\nsrc_host \u003d \"http://localhost:11000\"\nsrc_api_jey \u003d \"ABQFRE9MPCKRX8BAOHU6V5B9F2UFPZ1C\"\nsrc_client \u003d dataikuapi.DSSClient(host\u003dsrc_host, api_key\u003dsrc_api_jey)\n\nsrc_project_keys_list \u003d [\u0027DKU_CHURN\u0027]\n\nfor prj_key in src_project_keys_list:\n    \n    print(\u0027asdfa\u0027)\n    print(\u0027asdfo\u0027)\n    src_prj \u003d src_client.get_project(prj_key)\n\n    # load datasets list\n    dataset_list \u003d set()\n    src_datasets \u003d src_prj.list_datasets()\n    for dataset in src_datasets:\n        \n        dssdataset \u003d dataset.to_dataset()\n        settings \u003d dssdataset.get_settings()\n        raw_settings \u003d settings.get_raw()\n        \n        try:\n            if raw_settings[\u0027formatType\u0027] \u003d\u003d \u0027parquet\u0027:\n                print(\u0027here\u0027)\n                print(\"Convert dataset \" + raw_settings[\u0027name\u0027] + \" to ORC\")\n                settings.get_raw()[\u0027formatType\u0027] \u003d \u0027orcfile\u0027\n                settings.get_raw()[\u0027formatParams\u0027] \u003d { \u0027compressionMethod\u0027: \u0027SNAPPY\u0027, \u0027serdeClass\u0027: \u0027org.apache.hadoop.hive.ql.io.orc.OrcSerde\u0027, \u0027serdeProperties\u0027: {}, \u0027representsNullFields\u0027: False }\n                settings.save()\n                dssdataset.clear()\n                print(\u0027dun\u0027)\n        except:\n            print(\u0027oopps we did a fucky wucky\u0027)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\n \ndef update_trigger_script(trg_dict, new_trg_query_dict):\n    if trg_dict[\u0027id\u0027] in new_trg_query_dict.keys():\n        trg_dict[\u0027params\u0027][\u0027sql\u0027] \u003d new_trg_query_dict[trg_dict[\u0027id\u0027]]\n    return trg_dict\n \ndef main():\n \n    client \u003d dataiku.api_client() # set up API client\n   \n    pk \u003d \u0027DKU_CHURN\u0027\n    scn_id \u003d \u0027what\u0027\n    trg_id1 \u003d \u0027rV7yzlLz\u0027\n    trg_id2 \u003d \u0027cqU0lsQf\u0027\n   \n    project \u003d client.get_project(pk)\n \n    scn_settings \u003d project.get_scenario(scn_id).get_settings()\n    trg_lod \u003d scn_settings.get_raw()[\u0027triggers\u0027]\n    print(trg_lod)\n    new_trg_query_dict \u003d {trg_id1: \u0027new script 1\u0027, trg_id2: \u0027new script 2\u0027}\n    for x in scn_settings.raw_triggers:\n        update_trigger_script(x, new_trg_query_dict)\n    scn_settings.save()\n   \nif __name__ \u003d\u003d \"__main__\":\n    main()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}